{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"A7q5DjXenGU7"},"source":["# Semantic textual similarity\n","## Final Project IHLT - UPC 2022/2023\n","### Authors : Rob - Edison Bejarano\n","\n","1. Data\n","\n","2. What we are doing?\n","#### Techniques for preprocessing text for similarity comparison\n","\n","- Stemming: is a process that involves reducing words to their base form, or stem, in order to normalize the text and remove variations in word endings. For example, the words \"running,\" \"runs,\" and \"ran\" would all be reduced to the stem \"run\" by a stemming algorithm.\n","\n","\n","- Lemmatization: is a process that involves reducing words to their base form, or lemma, in order to normalize the text and remove variations in word endings. Unlike stemming, lemmatization takes into account the context of the word in order to determine its lemma, resulting in more accurate and meaningful reductions. For example, the words \"running,\" \"runs,\" and \"ran\" would all be reduced to the lemma \"run\" by a lemmatization algorithm.\n","\n","- Tf-idf weighting: Is a method for assigning a weight to each word in a document based on its relative importance. The weight is calculated by multiplying the term frequency (tf) of the word by the inverse document frequency (idf) of the word across all documents in a corpus. This weighting scheme gives higher weight to words that are more frequent within a document but less frequent across the corpus, making them more important for characterizing the document.\n","\n","- NES : Function used the Natural Language Toolkit (nltk) to identify named entities in a given sentence. The sentence parameter is the sentence in which named entities should be identified, and the binary parameter determines whether named entities should be grouped together or returned as individual tokens. The function returns a set of the named entities and individual words found in the sentence.\n","\n","\n","These techniques can be used in combination with each other or with stopwords removal to preprocess text and improve the accuracy of similarity comparison. For example, you could use stemming or lemmatization to normalize the words in the phrases, and then use tf-idf weighting to assign importance to each word based on its frequency within the phrases and across a larger corpus. This would allow you to compare the similarity of the phrases in a more meaningful and accurate way\n","\n","\n","3. Results"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Install packages"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/bin/fish: /home/rob/miniconda3/lib/libtinfo.so.6: no version information available (required by /usr/bin/fish)\n","/usr/bin/fish: /home/rob/miniconda3/lib/libstdc++.so.6: version `CXXABI_1.3.13' not found (required by /usr/bin/fish)\n","/usr/bin/fish: /home/rob/miniconda3/lib/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /usr/bin/fish)\n","/usr/bin/fish: /home/rob/miniconda3/lib/libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /usr/bin/fish)\n"]}],"source":["!pip install -q spacy nltk numpy pandas scikit-learn pyjarowinkler lazypredict"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Libraries"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1670661492620,"user":{"displayName":"Edison Bejarano Sepulveda","userId":"16974971435170261412"},"user_tz":-60},"id":"67vwZWxBcGZF","outputId":"9baddf20-b957-4e36-840a-a4e819f7f2d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /home/rob/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /home/rob/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package punkt to /home/rob/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /home/rob/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /home/rob/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package omw-1.4 to /home/rob/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package gutenberg to /home/rob/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package conll2000 to /home/rob/nltk_data...\n","[nltk_data]   Unzipping corpora/conll2000.zip.\n","[nltk_data] Downloading package brown to /home/rob/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package words to /home/rob/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import re\n","import nltk\n","import spacy\n","import string\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","from itertools import chain\n","from functools import partial\n","from argparse import Namespace\n","from pyjarowinkler import distance\n","\n","from nltk.wsd import lesk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.metrics import jaccard_distance\n","from nltk.corpus import stopwords, wordnet\n","\n","from scipy.stats import pearsonr\n","\n","from sklearn import linear_model\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import StandardScaler\n","from typing import List\n","from lazypredict.Supervised import LazyClassifier\n","\n","nltk.download('wordnet')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('omw-1.4')\n","nltk.download('gutenberg')\n","\n","nltk.download('conll2000')\n","nltk.download('brown')\n","nltk.download('words')"]},{"cell_type":"markdown","metadata":{"id":"TS52eWLnnJvr"},"source":["## Download data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1133,"status":"ok","timestamp":1669293565602,"user":{"displayName":"Edison Bejarano Sepulveda","userId":"16974971435170261412"},"user_tz":-60},"id":"k0hykeMvnNtn","outputId":"51914aeb-8ac8-45cb-d3ef-7d67bcd7a7c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2003  100  2003    0     0  47690      0 --:--:-- --:--:-- --:--:-- 47690\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  122k  100  122k    0     0   505k      0 --:--:-- --:--:-- --:--:--  503k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  115k  100  115k    0     0   345k      0 --:--:-- --:--:-- --:--:--  345k\n"]}],"source":["#!curl -o /content/drive/MyDrive/Colab_Notebooks/2.IHLT/final_project/trial.tgz https://gebakx.github.io/ihlt/sts/resources/trial.tgz\n","#!curl -o /content/drive/MyDrive/Colab_Notebooks/2.IHLT/final_project/train.tgz https://gebakx.github.io/ihlt/sts/resources/train.tgz\n","#!curl -o /content/drive/MyDrive/Colab_Notebooks/2.IHLT/final_project/test-gold.tgz https://gebakx.github.io/ihlt/sts/resources/test-gold.tgz"]},{"cell_type":"markdown","metadata":{"id":"a91zUN7nIF_h"},"source":["# Bring data"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1203,"status":"ok","timestamp":1670661368611,"user":{"displayName":"Edison Bejarano Sepulveda","userId":"16974971435170261412"},"user_tz":-60},"id":"jpDBKAHfpe-Z","outputId":"500addc2-c71a-4bfc-d5f4-ac57ba7d9dcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["train/\n","train/00-readme.txt\n","train/STS.output.MSRpar.txt\n","train/STS.input.SMTeuroparl.txt\n","train/STS.input.MSRpar.txt\n","train/STS.gs.MSRpar.txt\n","train/STS.input.MSRvid.txt\n","train/STS.gs.MSRvid.txt\n","train/correlation.pl\n","train/STS.gs.SMTeuroparl.txt\n","trial/\n","trial/STS.input.txt\n","trial/00-readme.txt\n","trial/STS.gs.txt\n","trial/STS.ouput.txt\n","test-gold/\n","test-gold/STS.input.MSRpar.txt\n","test-gold/STS.gs.MSRpar.txt\n","test-gold/STS.input.MSRvid.txt\n","test-gold/STS.gs.MSRvid.txt\n","test-gold/STS.input.SMTeuroparl.txt\n","test-gold/STS.gs.SMTeuroparl.txt\n","test-gold/STS.input.surprise.SMTnews.txt\n","test-gold/STS.gs.surprise.SMTnews.txt\n","test-gold/STS.input.surprise.OnWN.txt\n","test-gold/STS.gs.surprise.OnWN.txt\n","test-gold/STS.gs.ALL.txt\n","test-gold/00-readme.txt\n"]}],"source":["!tar zxvf ../final_project/train.tgz\n","!tar zxvf ../final_project/trial.tgz\n","!tar zxvf ../final_project/test-gold.tgz\n","\n","!rm ../final_project/train.tgz\n","!rm ../final_project/test-gold.tgz \n","!rm ../final_project/trial.tgz\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TLgFj_E7nKdQ"},"source":["# Usesful functions"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["# ------------------------------ #\n","# Lesk Function \n","# ------------------------------ #\n","def apply_jaccard_lesk(sentence1: str, sentence2: str):\n","\n","  # Apply lesk to sentence 1\n","  synset1 = [ lesk(sentence1, word) for word in sentence1 ]\n","  synset1 = { word for word in synset1 if word is not None }\n","\n","  # Apply lesk to sentence 1\n","  synset2 = [ lesk(sentence2, word) for word in sentence2 ]\n","  synset2 = { word for word in synset2 if word is not None }\n","\n","  # Calculate distance\n","  distance = jaccard_distance(synset1, synset2)\n","\n","  return distance\n","\n","\n","# ------------------------------ #\n","# Jaccard similarity Function\n","# ------------------------------ #\n","def jaccard_similarity(s1: List[str], s2: List[str]):\n","    s1 = set(s1)\n","    s2 = set(s2)\n","    intersection = len(s1.intersection(s2))\n","    union = len(s1) + len(s2) - intersection\n","    return float(intersection) / float(union)\n","\n","\n","# ------------------------------ #\n","# Jaccard Similarity List\n","# ------------------------------ #\n","def jaccard_similarity_list(s1: List[List[str]], s2: List[List[str]]):\n","    return np.array(list(map(jaccard_similarity, s1, s2)))\n","\n","# ------------------------------ #\n","# Dice Similarity Function\n","# ------------------------------ #\n","def dice_similarity(s1: List[str], s2: List[str]):\n","    s1 = set(s1)\n","    s2 = set(s2)\n","    intersection = s1.intersection(s2)\n","    return 2 * len(intersection) / (len(s1) + len(s2))\n","\n","# ------------------------------ #\n","# Jarowinkler Similarity\n","# ------------------------------ #   \n","def calculateJarowinklerSimilarity(dataframe, column1, column2):\n","\n","  aux = []\n","  for row in dataframe.itertuples():\n","    \n","    # Longest one selected\n","    if len(row[column1]) >= len(row[column2]):\n","      sentence1 = row[column1]\n","      sentence2 = row[column2]\n","    else:\n","      sentence1 = row[column2]\n","      sentence2 = row[column1]\n","\n","    similarities_array = []\n","    for word1 in sentence1:\n","      max = 0\n","\n","      for word2 in sentence2:\n","        similarity = distance.get_jaro_distance(str(word1), str(word2), winkler=True, scaling=0.1)\n","           \n","        if max < similarity:\n","          max = similarity\n","        \n","      similarities_array.append(max)\n","\n","    aux.append(np.array(similarities_array).mean())\n","\n","  return aux\n","   "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1_VF58N6nQre"},"outputs":[],"source":["# ------------------------------ #\n","#         Get Wordnet POS\n","# ------------------------------ #\n","def get_wordnet_pos(word):\n","    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"NN\": \"n\",\n","                \"NNS\": \"n\",\n","                \"NNP\": \"n\",\n","                \"NNPS\": \"n\",\n","                \"VB\": \"v\",\n","                \"VBD\": \"v\",\n","                \"VBG\": \"v\",\n","                \"VBN\": \"v\",\n","                \"VBP\": \"v\",\n","                \"VBZ\": \"v\",\n","                \"RB\": \"r\",\n","                \"RBR\": \"r\",\n","                \"RBS\": \"r\",\n","                \"JJ\": \"a\",\n","                \"JJR\": \"a\",\n","                \"JJS\": \"a\",}\n","        \n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","\n","# ------------------------------ #\n","#   Function to tokenize\n","# ------------------------------ #\n","def tokenize_column(column):\n","  #put in lowercase\n","  tokenized = [nltk.word_tokenize(sentence) for sentence in column]\n","  #Lowercase the tokens\n","  tokenized = [ [ word.lower() for word in sentence ] for sentence in tokenized ]\n","  return tokenized\n","\n","\n","\n","#--------------------------------------------#\n","#  Function to NES\n","#--------------------------------------------#\n","def NES(sentence: str, binary: bool):\n","  x = nltk.pos_tag(nltk.word_tokenize(sentence))\n","  res = nltk.ne_chunk(x, binary=binary)\n","  necs_and_words = set()\n","  for chunk in res:\n","        if hasattr(chunk, 'label'):\n","            # Add NE\n","            token = ' '.join(term[0] for term in chunk)\n","            necs_and_words.add(token)\n","        else:\n","            token = chunk[0]\n","            if token.isalnum():\n","                necs_and_words.add(token.lower())\n","  return necs_and_words \n"," #--------------------------------------------#\n"," # Function to get entities from a column\n"," # -------------------------------------------# \n","def get_entities_new(column):\n","    entities = []\n","    for sentence in column:\n","        entities.append(NES(sentence, False))\n","    return entities\n","\n","\n","\n","# ------------------------------ #\n","# Lemmatization text process\n","# ------------------------------ #\n","lemmatizer = WordNetLemmatizer()\n","# ------------------------------ #\n","#   Function to lemmatize\n","# ------------------------------ #\n","def lemmatize(column):\n","  \n","  lemmas = []\n","\n","  for sentence in tqdm(column):\n","    sentence_lemmas = []\n","    for word in nltk.word_tokenize(sentence):\n","      sentence_lemmas.append(lemmatizer.lemmatize(word.lower(), get_wordnet_pos(word.lower())))\n","    lemmas.append(sentence_lemmas)\n","\n","  return lemmas\n","\n","\n","# ------------------------------ #\n","#   Stopwords initialization\n","# ------------------------------ #\n","stopwords = nltk.corpus.stopwords.words(\"english\")\n","stopwords[:10]\n","stopwords += string.punctuation\n","stopwords += ['.', ',', ';', '.\"']\n","# ------------------------------ #\n","#   Function to remove stopwords\n","# ------------------------------ #\n","def remove_stopwords(column):\n","  tokenized = [nltk.word_tokenize(sentence) for sentence in column]\n","  #Lowercase the tokens\n","  tokenized = [ [ word.lower() for word in sentence ] for sentence in tokenized ]\n","  return [ [ word for word in sentence if word not in stopwords ] for sentence in tokenized ]\n","\n","\n","# ------------------------------ #\n","#   Function to synonimize\n","# ------------------------------ #\n","def synonimize_column(column):\n","  #put in lowercase\n","  tokenized = [nltk.word_tokenize(sentence) for sentence in column]\n","  #Lowercase the tokens\n","  tokenized = [ [ word.lower() for word in sentence ] for sentence in tokenized ]\n","  #Synonimize\n","  synonimized = [ [ word for word in sentence if word not in stopwords ] for sentence in tokenized ]\n","\n","  return synonimized\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Functions of preprocessing\n","def read_data(text_datas: List[str], gs_datas: List[str]):\n","  all_df_text = []\n","  for text_data, gs_data in zip(text_datas, gs_datas):\n","    df_text = pd.read_csv(text_data, sep=r'\\t', engine='python', header=None)\n","    df_text.columns = [\"text1\", \"text2\"]\n","    df_text['gs'] = pd.read_csv(gs_data, sep='\\t', header=None)\n","    all_df_text.append(df_text.dropna())\n","  return pd.concat(all_df_text)\n","\n","def get_dataset(path: str) -> pd.DataFrame:\n","  files = sorted(os.listdir(path))\n","  input_files = [ os.path.join(path, file) for file in files if 'input' in file ]\n","  gs_files = [ os.path.join(path, file) for file in files if 'gs' in file ]\n","  df = read_data(input_files, gs_files)\n","  return df"]},{"cell_type":"markdown","metadata":{"id":"wm2VxdulsYgE"},"source":["# Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"TfqKCsKhN3fR"},"source":["### Data information\n","- trial : includes the definition of the scores, a sample of 5 sentence pairs and the input and output formats. It is not needed, but it is useful for prototyping.\n","\n","- train : training data from paraphrasing data sets, input and output formats.\n","\n","- test : test data from paraphrasing data sets."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1670661604957,"user":{"displayName":"Edison Bejarano Sepulveda","userId":"16974971435170261412"},"user_tz":-60},"id":"QdEvE55Xsb0L"},"outputs":[],"source":["train_path = '../final_project/train'\n","trial_path = '../final_project/trial'\n","test_path  = '../final_project/test-gold'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Similarities**"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["\n","train_dataset_pruebas = get_dataset(train_path)\n","test_dataset_pruebas = get_dataset(test_path)\n","df = train_dataset_pruebas\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2234/2234 [00:03<00:00, 592.03it/s] \n","100%|██████████| 2234/2234 [00:02<00:00, 795.33it/s] \n","100%|██████████| 2234/2234 [00:01<00:00, 1223.84it/s]\n"]}],"source":["# Tokenization features\n","tokenized_text1 = tokenize_column(df['text1'])\n","tokenized_text2 = tokenize_column(df['text2'])\n","\n","# Lemmatization features\n","lemmatize_text1 = lemmatize(df['text1'])\n","lemmatize_text2 = lemmatize(df['text2'])\n","\n","\n","#Use stopwords function to remove stopwords\n","stopwords_text1 = remove_stopwords(df['text1'])\n","stopwords_text2 = remove_stopwords(df['text2'])\n","\n","\n","\n","# Synonyms features\n","synonyms_text1 = []\n","synonyms_text2 = []\n","# Use sysnstesizer to get synonyms\n","for i in tqdm(range(len(tokenized_text1))):\n","    synonyms_text1.append([syn for w in tokenized_text1[i] for syn in wordnet.synsets(w)])\n","    synonyms_text2.append([syn for w in tokenized_text2[i] for syn in wordnet.synsets(w)])\n","\n","\n","# Synonyms features another way\n","synonimized_text1_new = synonimize_column(df['text1'])\n","synonimized_text2_new = synonimize_column(df['text2'])\n","\n","\n","# NES features\n","NES_column_text1 = get_entities_new(df['text1'])\n","NES_column_text2 = get_entities_new(df['text2'])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Jaccard similarity tokenized:  [0.5483871  0.42105263 0.34782609]\n","Jaccard similarity lemmatize:  [0.5483871  0.42105263 0.34782609]\n","Jaccard similarity stopwords:  [0.47368421 0.46153846 0.33333333]\n","Jaccard similarity synonyms:  [0.67680608 0.30172414 0.38562092]\n","Jaccard similarity synonyms new:  [0.47368421 0.46153846 0.33333333]\n"]}],"source":["# Jaccard similarity features\n","jaccard_similarity_tokenized = jaccard_similarity_list(tokenized_text1, tokenized_text2)\n","jaccard_similarity_synonyms_new = jaccard_similarity_list(synonimized_text1_new, synonimized_text2_new)\n","jaccard_similarity_NES = jaccard_similarity_list(NES_column_text1, NES_column_text2)\n","\n","jaccard_similarity_lemmatize = jaccard_similarity_list(lemmatize_text1, lemmatize_text2)\n","jaccard_similarity_stopwords = jaccard_similarity_list(stopwords_text1, stopwords_text2)\n","jaccard_similarity_synonyms = jaccard_similarity_list(synonyms_text1, synonyms_text2)\n","\n","\n","print(\"Jaccard similarity tokenized: \", jaccard_similarity_tokenized[:3])\n","print(\"Jaccard similarity lemmatize: \", jaccard_similarity_lemmatize[:3])\n","print(\"Jaccard similarity stopwords: \", jaccard_similarity_stopwords[:3])\n","print(\"Jaccard similarity synonyms: \", jaccard_similarity_synonyms[:3])\n","print(\"Jaccard similarity synonyms new: \", jaccard_similarity_synonyms_new[:3])\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text1</th>\n","      <th>text2</th>\n","      <th>gs</th>\n","      <th>tokenized_text1</th>\n","      <th>tokenized_text2</th>\n","      <th>lemmatize_text1</th>\n","      <th>lemmatize_text2</th>\n","      <th>stopwords_text1</th>\n","      <th>stopwords_text2</th>\n","      <th>synonyms_text1</th>\n","      <th>synonyms_text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>But other sources close to the sale said Viven...</td>\n","      <td>But other sources close to the sale said Viven...</td>\n","      <td>4.00</td>\n","      <td>[but, other, sources, close, to, the, sale, sa...</td>\n","      <td>[but, other, sources, close, to, the, sale, sa...</td>\n","      <td>[but, other, source, close, to, the, sale, sai...</td>\n","      <td>[but, other, source, close, to, the, sale, sai...</td>\n","      <td>[sources, close, sale, said, vivendi, keeping,...</td>\n","      <td>[sources, close, sale, said, vivendi, keeping,...</td>\n","      <td>[Synset('merely.r.01'), Synset('other.a.01'), ...</td>\n","      <td>[Synset('merely.r.01'), Synset('other.a.01'), ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Micron has declared its first quarterly profit...</td>\n","      <td>Micron's numbers also marked the first quarter...</td>\n","      <td>3.75</td>\n","      <td>[micron, has, declared, its, first, quarterly,...</td>\n","      <td>[micron, 's, numbers, also, marked, the, first...</td>\n","      <td>[micron, ha, declared, it, first, quarterly, p...</td>\n","      <td>[micron, 's, number, also, marked, the, first,...</td>\n","      <td>[micron, declared, first, quarterly, profit, t...</td>\n","      <td>[micron, 's, numbers, also, marked, first, qua...</td>\n","      <td>[Synset('micron.n.01'), Synset('hour_angle.n.0...</td>\n","      <td>[Synset('micron.n.01'), Synset('numbers.n.01')...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The fines are part of failed Republican effort...</td>\n","      <td>Perry said he backs the Senate's efforts, incl...</td>\n","      <td>2.80</td>\n","      <td>[the, fines, are, part, of, failed, republican...</td>\n","      <td>[perry, said, he, backs, the, senate, 's, effo...</td>\n","      <td>[the, fine, are, part, of, failed, republican,...</td>\n","      <td>[perry, said, he, back, the, senate, 's, effor...</td>\n","      <td>[fines, part, failed, republican, efforts, for...</td>\n","      <td>[perry, said, backs, senate, 's, efforts, incl...</td>\n","      <td>[Synset('fine.n.01'), Synset('ticket.v.01'), S...</td>\n","      <td>[Synset('perry.n.01'), Synset('perry.n.02'), S...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The American Anglican Council, which represent...</td>\n","      <td>The American Anglican Council, which represent...</td>\n","      <td>3.40</td>\n","      <td>[the, american, anglican, council, ,, which, r...</td>\n","      <td>[the, american, anglican, council, ,, which, r...</td>\n","      <td>[the, american, anglican, council, ,, which, r...</td>\n","      <td>[the, american, anglican, council, ,, which, r...</td>\n","      <td>[american, anglican, council, represents, epis...</td>\n","      <td>[american, anglican, council, represents, epis...</td>\n","      <td>[Synset('american.n.01'), Synset('american_eng...</td>\n","      <td>[Synset('american.n.01'), Synset('american_eng...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n","      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n","      <td>2.40</td>\n","      <td>[the, tech-loaded, nasdaq, composite, rose, 20...</td>\n","      <td>[the, technology-laced, nasdaq, composite, ind...</td>\n","      <td>[the, tech-loaded, nasdaq, composite, rose, 20...</td>\n","      <td>[the, technology-laced, nasdaq, composite, ind...</td>\n","      <td>[tech-loaded, nasdaq, composite, rose, 20.96, ...</td>\n","      <td>[technology-laced, nasdaq, composite, index, ....</td>\n","      <td>[Synset('national_association_of_securities_de...</td>\n","      <td>[Synset('national_association_of_securities_de...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               text1  \\\n","0  But other sources close to the sale said Viven...   \n","1  Micron has declared its first quarterly profit...   \n","2  The fines are part of failed Republican effort...   \n","3  The American Anglican Council, which represent...   \n","4  The tech-loaded Nasdaq composite rose 20.96 po...   \n","\n","                                               text2   gs  \\\n","0  But other sources close to the sale said Viven... 4.00   \n","1  Micron's numbers also marked the first quarter... 3.75   \n","2  Perry said he backs the Senate's efforts, incl... 2.80   \n","3  The American Anglican Council, which represent... 3.40   \n","4  The technology-laced Nasdaq Composite Index <.... 2.40   \n","\n","                                     tokenized_text1  \\\n","0  [but, other, sources, close, to, the, sale, sa...   \n","1  [micron, has, declared, its, first, quarterly,...   \n","2  [the, fines, are, part, of, failed, republican...   \n","3  [the, american, anglican, council, ,, which, r...   \n","4  [the, tech-loaded, nasdaq, composite, rose, 20...   \n","\n","                                     tokenized_text2  \\\n","0  [but, other, sources, close, to, the, sale, sa...   \n","1  [micron, 's, numbers, also, marked, the, first...   \n","2  [perry, said, he, backs, the, senate, 's, effo...   \n","3  [the, american, anglican, council, ,, which, r...   \n","4  [the, technology-laced, nasdaq, composite, ind...   \n","\n","                                     lemmatize_text1  \\\n","0  [but, other, source, close, to, the, sale, sai...   \n","1  [micron, ha, declared, it, first, quarterly, p...   \n","2  [the, fine, are, part, of, failed, republican,...   \n","3  [the, american, anglican, council, ,, which, r...   \n","4  [the, tech-loaded, nasdaq, composite, rose, 20...   \n","\n","                                     lemmatize_text2  \\\n","0  [but, other, source, close, to, the, sale, sai...   \n","1  [micron, 's, number, also, marked, the, first,...   \n","2  [perry, said, he, back, the, senate, 's, effor...   \n","3  [the, american, anglican, council, ,, which, r...   \n","4  [the, technology-laced, nasdaq, composite, ind...   \n","\n","                                     stopwords_text1  \\\n","0  [sources, close, sale, said, vivendi, keeping,...   \n","1  [micron, declared, first, quarterly, profit, t...   \n","2  [fines, part, failed, republican, efforts, for...   \n","3  [american, anglican, council, represents, epis...   \n","4  [tech-loaded, nasdaq, composite, rose, 20.96, ...   \n","\n","                                     stopwords_text2  \\\n","0  [sources, close, sale, said, vivendi, keeping,...   \n","1  [micron, 's, numbers, also, marked, first, qua...   \n","2  [perry, said, backs, senate, 's, efforts, incl...   \n","3  [american, anglican, council, represents, epis...   \n","4  [technology-laced, nasdaq, composite, index, ....   \n","\n","                                      synonyms_text1  \\\n","0  [Synset('merely.r.01'), Synset('other.a.01'), ...   \n","1  [Synset('micron.n.01'), Synset('hour_angle.n.0...   \n","2  [Synset('fine.n.01'), Synset('ticket.v.01'), S...   \n","3  [Synset('american.n.01'), Synset('american_eng...   \n","4  [Synset('national_association_of_securities_de...   \n","\n","                                      synonyms_text2  \n","0  [Synset('merely.r.01'), Synset('other.a.01'), ...  \n","1  [Synset('micron.n.01'), Synset('numbers.n.01')...  \n","2  [Synset('perry.n.01'), Synset('perry.n.02'), S...  \n","3  [Synset('american.n.01'), Synset('american_eng...  \n","4  [Synset('national_association_of_securities_de...  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["#put everythiong in a dataframe\n","df['tokenized_text1'] = tokenized_text1\n","df['tokenized_text2'] = tokenized_text2\n","df['lemmatize_text1'] = lemmatize_text1\n","df['lemmatize_text2'] = lemmatize_text2\n","df['stopwords_text1'] = stopwords_text1\n","df['stopwords_text2'] = stopwords_text2\n","df['synonyms_text1'] = synonyms_text1\n","df['synonyms_text2'] = synonyms_text2\n","df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":388,"status":"error","timestamp":1670662891072,"user":{"displayName":"Edison Bejarano Sepulveda","userId":"16974971435170261412"},"user_tz":-60},"id":"0tx_t_KsL_Fl","outputId":"842eff73-ae95-4a78-d46c-ecf589fd656c"},"outputs":[],"source":["def get_features(df: pd.DataFrame):\n","\n","    #--------------------------------------------#\n","    # 0. NLTK Words features\n","    #--------------------------------------------#\n","    #print(\"NLTK Words features\")\n","    \n","    #nltk_words_text1 = []\n","    #nltk_words_text2 = []\n","\n","    #--------------------------------------------#\n","    # 1. Tokenize features\n","    #--------------------------------------------#    \n","    tokenized_text1 = tokenize_column(df['text1'])\n","    tokenized_text2 = tokenize_column(df['text2'])\n","\n","    #--------------------------------------------#\n","    # 2. Lemmatize features\n","    #--------------------------------------------#\n","    lemmatize_text1 = lemmatize(df['text1'])\n","    lemmatize_text2 = lemmatize(df['text2'])\n","\n","\n","    #--------------------------------------------#\n","    # 3. Stopwords features\n","    #--------------------------------------------#   \n","    stopwords_text1 = remove_stopwords(df['text1'])\n","    stopwords_text2 = remove_stopwords(df['text2'])\n","\n","\n","\n","    #--------------------------------------------#\n","    # 4. Synonims features\n","    #--------------------------------------------#\n","    synonyms_text1 = []\n","    synonyms_text2 = []\n","    # Use sysnstesizer to get synonyms\n","    for i in tqdm(range(len(tokenized_text1))):\n","        synonyms_text1.append([syn for w in tokenized_text1[i] for syn in wordnet.synsets(w)])\n","        synonyms_text2.append([syn for w in tokenized_text2[i] for syn in wordnet.synsets(w)])\n","\n","\n","\n","    \n","    #--------------------------------------------#\n","    # 4. NES features\n","    #--------------------------------------------#\n","    NES_column_text1 = get_entities_new(df['text1'])\n","    NES_column_text2 = get_entities_new(df['text2'])\n","    \n","\n","    #--------------------------------------------#\n","    # 5. Synset features\n","    #--------------------------------------------#\n","    #print(\"Synset features\")\n","    #synset_text1 = [wordnet.synsets(phrase)[0] for phrase in tqdm(lemmatize_text1)]\n","    #synset_text2 = [wordnet.synsets(phrase)[0] for phrase in tqdm(lemmatize_text2)]\n","\n","\n","    #--------------------------------------------#\n","    # 6. Spacy words features\n","    #--------------------------------------------#\n","    #print(\"Spacy words features\")\n","    #spacy_words_text1 = []\n","    #spacy_words_text2 = []\n","\n","\n","    #--------------------------------------------#\n","    # 7. Ngrams features\n","    #--------------------------------------------#\n","    #print(\"Ngrams features\")\n","    #ngrams_text1 = []\n","\n","    #--------------------------------------------#\n","    # 8.Word synonyms features\n","    #--------------------------------------------#\n","    #print(\"Word synonyms features\")\n","\n","\n","    features = [\n","            jaccard_similarity_list(tokenized_text1, tokenized_text2),\n","            # jaccard_similarity(tokenized_lc_1, tokenized_lc_2),\n","            # jaccard_similarity(no_stopwords_1, no_stopwords_2),\n","            jaccard_similarity_list(stopwords_text1, stopwords_text2),\n","            # jaccard_similarity(lemmatized_1, lemmatized_2),\n","            # jaccard_similarity(lemmatized_lc_1, lemmatized_lc_2),\n","            jaccard_similarity_list(sentence_ne_1, sentence_ne_2),\n","            jaccard_similarity_list(stopwords_and_lemmas1, stopwords_and_lemmas2),\n","            # jaccard_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n","            # jaccard_similarity(bigrams_1, bigrams_2),\n","            jaccard_similarity_list(trigrams_1, trigrams_2),\n","            # jaccard_similarity(bigrams_sent_1, bigrams_sent_2),\n","            jaccard_similarity_list(trigrams_sent_1, trigrams_sent_2),\n","            jaccard_similarity_list(lesk_1, lesk_2),\n","            jaccard_similarity_list(lesk_lc_1, lesk_lc_2),\n","            jaccard_similarity_list(stemmed_1, stemmed_2),\n","            dice_similarity(tokenized_text1, tokenized_text2),\n","            # dice_similarity(tokenized_lc_1, tokenized_lc_2),\n","            dice_similarity(stopwords_text1, stopwords_text2),\n","            dice_similarity(no_stopwords_lc_1, no_stopwords_lc_2),\n","            # dice_similarity(lemmatized_1, lemmatized_2),\n","            # dice_similarity(lemmatized_lc_1, lemmatized_lc_2),\n","            # dice_similarity(sentence_ne_1, sentence_ne_2),\n","            # dice_similarity(stopwords_and_lemmas1, stopwords_and_lemmas2),\n","            dice_similarity(stopwords_and_lemmas_lc_1, stopwords_and_lemmas_lc_2),\n","            dice_similarity(bigrams_1, bigrams_2),\n","            # dice_similarity(trigrams_1, trigrams_2),\n","            # dice_similarity(bigrams_sent_1, bigrams_sent_2),\n","            # dice_similarity(trigrams_sent_1, trigrams_sent_2),\n","            # dice_similarity(lesk_1, lesk_2),\n","            # dice_similarity(lesk_lc_1, lesk_lc_2),\n","            # dice_similarity(stemmed_1, stemmed_2),\n","            # average_path,\n","            # average_lch,\n","            # average_wup,\n","            average_lin,\n","            # average_lc_path,\n","            average_lc_lch,\n","            average_lc_wup,\n","            average_lc_lin\n","    ]\n","    return np.array(features)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Training**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get training dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"fifhUTGhRKBS"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2234, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text1</th>\n","      <th>text2</th>\n","      <th>gs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>But other sources close to the sale said Viven...</td>\n","      <td>But other sources close to the sale said Viven...</td>\n","      <td>4.00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Micron has declared its first quarterly profit...</td>\n","      <td>Micron's numbers also marked the first quarter...</td>\n","      <td>3.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The fines are part of failed Republican effort...</td>\n","      <td>Perry said he backs the Senate's efforts, incl...</td>\n","      <td>2.80</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The American Anglican Council, which represent...</td>\n","      <td>The American Anglican Council, which represent...</td>\n","      <td>3.40</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n","      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n","      <td>2.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               text1  \\\n","0  But other sources close to the sale said Viven...   \n","1  Micron has declared its first quarterly profit...   \n","2  The fines are part of failed Republican effort...   \n","3  The American Anglican Council, which represent...   \n","4  The tech-loaded Nasdaq composite rose 20.96 po...   \n","\n","                                               text2   gs  \n","0  But other sources close to the sale said Viven... 4.00  \n","1  Micron's numbers also marked the first quarter... 3.75  \n","2  Perry said he backs the Senate's efforts, incl... 2.80  \n","3  The American Anglican Council, which represent... 3.40  \n","4  The technology-laced Nasdaq Composite Index <.... 2.40  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = get_dataset(train_path)\n","print(train_dataset.shape)\n","train_dataset.head()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(2234,)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["y_train = train_dataset['gs'].values\n","y_train.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get features of the training dataset"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2234/2234 [00:02<00:00, 780.85it/s] \n","100%|██████████| 2234/2234 [00:03<00:00, 720.50it/s] \n","100%|██████████| 2234/2234 [00:00<00:00, 3391.78it/s]\n"]},{"data":{"text/plain":["(5, 2234)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["X_train_features: np.ndarray = get_features(train_dataset)\n","X_train_features.shape"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["(5, 2234)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["X_train_features.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Testing**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get the test dataset"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(2817, 3)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text1</th>\n","      <th>text2</th>\n","      <th>gs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The problem likely will mean corrective change...</td>\n","      <td>He said the problem needs to be corrected befo...</td>\n","      <td>4.40</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The technology-laced Nasdaq Composite Index .I...</td>\n","      <td>The broad Standard &amp; Poor's 500 Index .SPX inc...</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"It's a huge black eye,\" said publisher Arthur...</td>\n","      <td>\"It's a huge black eye,\" Arthur Sulzberger, th...</td>\n","      <td>3.60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>SEC Chairman William Donaldson said there is a...</td>\n","      <td>\"I think there's a building confidence that th...</td>\n","      <td>3.40</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Vivendi shares closed 1.9 percent at 15.80 eur...</td>\n","      <td>In New York, Vivendi shares were 1.4 percent d...</td>\n","      <td>1.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               text1  \\\n","0  The problem likely will mean corrective change...   \n","1  The technology-laced Nasdaq Composite Index .I...   \n","2  \"It's a huge black eye,\" said publisher Arthur...   \n","3  SEC Chairman William Donaldson said there is a...   \n","4  Vivendi shares closed 1.9 percent at 15.80 eur...   \n","\n","                                               text2   gs  \n","0  He said the problem needs to be corrected befo... 4.40  \n","1  The broad Standard & Poor's 500 Index .SPX inc... 0.80  \n","2  \"It's a huge black eye,\" Arthur Sulzberger, th... 3.60  \n","3  \"I think there's a building confidence that th... 3.40  \n","4  In New York, Vivendi shares were 1.4 percent d... 1.40  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset = get_dataset(test_path)\n","print(test_dataset.shape)\n","test_dataset.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get features of the test dataset"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2817/2817 [00:02<00:00, 1188.57it/s]\n","100%|██████████| 2817/2817 [00:02<00:00, 1124.52it/s]\n","100%|██████████| 2817/2817 [00:00<00:00, 5148.96it/s]\n"]},{"data":{"text/plain":["(5, 2817)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["X_test_features: np.ndarray = get_features(test_dataset)\n","X_test_features.shape"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["(2817,)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["y_test = test_dataset['gs'].values\n","y_test.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Normalize all features"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# Normalize the data\n","scaler = StandardScaler()\n","scaler.fit(X_train_features.T)\n","X_train_features_norm = scaler.transform(X_train_features.T)\n","X_test_features_norm = scaler.transform(X_test_features.T)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train the model"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train_features shape:  (2234, 5)\n","y_train shape:  (2234,)\n","X_test_features shape:  (2817, 5)\n","y_test shape:  (2817,)\n"]}],"source":["# Print all shapes\n","print(\"X_train_features shape: \", X_train_features_norm.shape)\n","print(\"y_train shape: \", y_train.shape)\n","print(\"X_test_features shape: \", X_test_features_norm.shape)\n","print(\"y_test shape: \", y_test.shape)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.43297584606538875\n"]}],"source":["# Create a linear regression\n","from sklearn.linear_model import LinearRegression\n","reg = LinearRegression()\n","reg.fit(X_train_features_norm, y_train)\n","print(reg.score(X_train_features_norm, y_train))"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["-0.7789083423779193"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["reg.score(X_test_features_norm, y_test)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5051, 5) (5051,)\n"]}],"source":["from sklearn.model_selection import GridSearchCV, PredefinedSplit\n","all_data = np.concatenate([X_train_features_norm, X_test_features_norm])\n","all_labels = np.concatenate([y_train, y_test])\n","test_fold = np.array([-1]*X_train_features_norm.shape[0] + [0]*X_test_features_norm.shape[0])\n","print(all_data.shape, test_fold.shape)\n","ps = PredefinedSplit(test_fold)"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["from sklearn.metrics import make_scorer\n","def pearsonr_scorer(y_true, y_pred):\n","    assert len(y_true) == len(y_pred)\n","    score = pearsonr(y_true, y_pred)[0]\n","    print(score)\n","    return score\n","pearson_scorer = make_scorer(pearsonr_scorer)\n","pearson_scorer.__name__ = 'pearson_scorer'\n","from sklearn.svm import SVR\n","\n","param = {\n","    \"hidden_layer_sizes\": [(1,),(50,), (100,), (200,)],\n","    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n","    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"], \"alpha\": [0.00005,0.0005]\n","}"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 1 folds for each of 96 candidates, totalling 96 fits\n"]},{"name":"stderr","output_type":"stream","text":["/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/home/rob/miniconda3/envs/ihlt/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:536: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"]}],"source":["\n","svr = MLPRegressor()\n","gssvr = GridSearchCV(svr,\n","                     param,\n","                     cv=ps,\n","                     scoring=pearson_scorer,\n","                     n_jobs=-1,\n","                     verbose=1)\n","gssvr = gssvr.fit(all_data, all_labels)"]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[],"source":["best_parameters = gssvr.best_params_\n","best_model = MLPRegressor(**best_parameters)\n","train_predictions = best_model.fit(X_train_features_norm, y_train).predict(X_train_features_norm)\n","test_predictions = best_model.predict(X_test_features_norm)"]},{"cell_type":"code","execution_count":147,"metadata":{},"outputs":[],"source":["train_correlation = pearsonr(train_predictions, y_train)[0]\n","test_correlation = pearsonr(test_predictions, y_test)[0]"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train pearsonr:  0.6576206453844373\n","Test pearsonr:  0.028328304162718896\n"]}],"source":["print('Train pearsonr: ', train_correlation)\n","print('Test pearsonr: ', test_correlation)"]},{"cell_type":"code","execution_count":137,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('AdaBoostRegressor', <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>), ('BaggingRegressor', <class 'sklearn.ensemble._bagging.BaggingRegressor'>), ('BayesianRidge', <class 'sklearn.linear_model._bayes.BayesianRidge'>), ('DecisionTreeRegressor', <class 'sklearn.tree._classes.DecisionTreeRegressor'>), ('DummyRegressor', <class 'sklearn.dummy.DummyRegressor'>), ('ElasticNet', <class 'sklearn.linear_model._coordinate_descent.ElasticNet'>), ('ElasticNetCV', <class 'sklearn.linear_model._coordinate_descent.ElasticNetCV'>), ('ExtraTreeRegressor', <class 'sklearn.tree._classes.ExtraTreeRegressor'>), ('ExtraTreesRegressor', <class 'sklearn.ensemble._forest.ExtraTreesRegressor'>), ('GammaRegressor', <class 'sklearn.linear_model._glm.glm.GammaRegressor'>), ('GaussianProcessRegressor', <class 'sklearn.gaussian_process._gpr.GaussianProcessRegressor'>), ('GradientBoostingRegressor', <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>), ('HistGradientBoostingRegressor', <class 'sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingRegressor'>), ('HuberRegressor', <class 'sklearn.linear_model._huber.HuberRegressor'>), ('KNeighborsRegressor', <class 'sklearn.neighbors._regression.KNeighborsRegressor'>), ('KernelRidge', <class 'sklearn.kernel_ridge.KernelRidge'>), ('Lars', <class 'sklearn.linear_model._least_angle.Lars'>), ('LarsCV', <class 'sklearn.linear_model._least_angle.LarsCV'>), ('Lasso', <class 'sklearn.linear_model._coordinate_descent.Lasso'>), ('LassoCV', <class 'sklearn.linear_model._coordinate_descent.LassoCV'>), ('LassoLars', <class 'sklearn.linear_model._least_angle.LassoLars'>), ('LassoLarsCV', <class 'sklearn.linear_model._least_angle.LassoLarsCV'>), ('LassoLarsIC', <class 'sklearn.linear_model._least_angle.LassoLarsIC'>), ('LinearRegression', <class 'sklearn.linear_model._base.LinearRegression'>), ('LinearSVR', <class 'sklearn.svm._classes.LinearSVR'>), ('MLPRegressor', <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>), ('NuSVR', <class 'sklearn.svm._classes.NuSVR'>), ('OrthogonalMatchingPursuit', <class 'sklearn.linear_model._omp.OrthogonalMatchingPursuit'>), ('OrthogonalMatchingPursuitCV', <class 'sklearn.linear_model._omp.OrthogonalMatchingPursuitCV'>), ('PassiveAggressiveRegressor', <class 'sklearn.linear_model._passive_aggressive.PassiveAggressiveRegressor'>), ('PoissonRegressor', <class 'sklearn.linear_model._glm.glm.PoissonRegressor'>), ('RANSACRegressor', <class 'sklearn.linear_model._ransac.RANSACRegressor'>), ('RandomForestRegressor', <class 'sklearn.ensemble._forest.RandomForestRegressor'>), ('Ridge', <class 'sklearn.linear_model._ridge.Ridge'>), ('RidgeCV', <class 'sklearn.linear_model._ridge.RidgeCV'>), ('SGDRegressor', <class 'sklearn.linear_model._stochastic_gradient.SGDRegressor'>), ('SVR', <class 'sklearn.svm._classes.SVR'>), ('TransformedTargetRegressor', <class 'sklearn.compose._target.TransformedTargetRegressor'>), ('TweedieRegressor', <class 'sklearn.linear_model._glm.glm.TweedieRegressor'>), ('XGBRegressor', <class 'xgboost.sklearn.XGBRegressor'>), ('LGBMRegressor', <class 'lightgbm.sklearn.LGBMRegressor'>)]\n"]}],"source":["from lazypredict.Supervised import REGRESSORS\n","REGRESSORS = [ c for c in REGRESSORS if c[0] != 'QuantileRegressor' ]\n","print(REGRESSORS)"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["'tuple' object has no attribute '__name__'\n","Invalid Regressor(s)\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 2/41 [00:00<00:02, 14.66it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.0634596333397755\n","-0.07987543333707416\n","0.032348320400756754\n","-0.07673337392739445\n","nan\n","-0.051353035800379615\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 7/41 [00:00<00:01, 25.98it/s]"]},{"name":"stdout","output_type":"stream","text":["0.02863492676706457\n","-0.07823878108677704\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 10/41 [00:00<00:02, 13.98it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.08056254282695005\n","-0.026435763448017128\n"]},{"name":"stderr","output_type":"stream","text":[" 29%|██▉       | 12/41 [00:01<00:04,  6.50it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.09260760820621453\n"]},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 14/41 [00:02<00:08,  3.26it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.0734295568354714\n","0.04100837525433105\n","-0.06889333626201584\n"]},{"name":"stderr","output_type":"stream","text":[" 49%|████▉     | 20/41 [00:03<00:03,  6.50it/s]"]},{"name":"stdout","output_type":"stream","text":["0.031736644824700455\n","0.033274248336098065\n","0.033274248336098065\n","nan\n","0.03143706912083802\n","nan\n","0.033274248336098065\n","0.033274248336098065\n","0.03327424833609599\n","0.03998623957091646\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 26/41 [00:05<00:03,  4.27it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.05313905564012349\n"]},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 28/41 [00:05<00:02,  4.64it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.05493927122631131\n","-0.0513530358003796\n","0.03327424833609833\n","-0.005543871375680092\n"]},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 31/41 [00:05<00:01,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.05140853373358763\n","0.05721888503847159\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 33/41 [00:06<00:01,  4.42it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.07662911200395438\n","0.03173664482467233\n","0.033115770655412435\n","0.016753109501593248\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 37/41 [00:06<00:00,  5.64it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.06335532499268984\n","0.03327424833609599\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 39/41 [00:07<00:00,  5.83it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.07197965343307115\n"]},{"name":"stderr","output_type":"stream","text":[" 98%|█████████▊| 40/41 [00:07<00:00,  5.25it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.09148560276598611\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 41/41 [00:07<00:00,  5.35it/s]"]},{"name":"stdout","output_type":"stream","text":["-0.07506677277338361\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from lazypredict.Supervised import LazyRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn import datasets\n","\n","# fit all models\n","reg = LazyRegressor(predictions=True, regressors=REGRESSORS, custom_metric=pearsonr_scorer)\n","regresion_models, regresion_predictions = reg.fit(X_train_features_norm, X_test_features_norm, y_train, y_test)"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Adjusted R-Squared</th>\n","      <th>R-Squared</th>\n","      <th>RMSE</th>\n","      <th>Time Taken</th>\n","      <th>pearsonr_scorer</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Lasso</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.02</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLars</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.01</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>DummyRegressor</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.01</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNet</th>\n","      <td>-0.10</td>\n","      <td>-0.10</td>\n","      <td>1.23</td>\n","      <td>0.02</td>\n","      <td>-0.05</td>\n","    </tr>\n","    <tr>\n","      <th>TweedieRegressor</th>\n","      <td>-0.42</td>\n","      <td>-0.41</td>\n","      <td>1.39</td>\n","      <td>0.29</td>\n","      <td>-0.07</td>\n","    </tr>\n","    <tr>\n","      <th>PoissonRegressor</th>\n","      <td>-0.57</td>\n","      <td>-0.57</td>\n","      <td>1.47</td>\n","      <td>0.45</td>\n","      <td>-0.05</td>\n","    </tr>\n","    <tr>\n","      <th>SGDRegressor</th>\n","      <td>-0.66</td>\n","      <td>-0.65</td>\n","      <td>1.51</td>\n","      <td>0.01</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>RANSACRegressor</th>\n","      <td>-0.69</td>\n","      <td>-0.69</td>\n","      <td>1.52</td>\n","      <td>0.09</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>AdaBoostRegressor</th>\n","      <td>-0.74</td>\n","      <td>-0.74</td>\n","      <td>1.55</td>\n","      <td>0.07</td>\n","      <td>-0.06</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNetCV</th>\n","      <td>-0.77</td>\n","      <td>-0.76</td>\n","      <td>1.56</td>\n","      <td>0.10</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>LinearSVR</th>\n","      <td>-0.77</td>\n","      <td>-0.76</td>\n","      <td>1.56</td>\n","      <td>0.02</td>\n","      <td>0.04</td>\n","    </tr>\n","    <tr>\n","      <th>LassoCV</th>\n","      <td>-0.77</td>\n","      <td>-0.77</td>\n","      <td>1.56</td>\n","      <td>0.09</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>Ridge</th>\n","      <td>-0.78</td>\n","      <td>-0.77</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>BayesianRidge</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>RidgeCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>TransformedTargetRegressor</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>LinearRegression</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsIC</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.02</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>LarsCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.02</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>Lars</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>OrthogonalMatchingPursuitCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>HuberRegressor</th>\n","      <td>-0.80</td>\n","      <td>-0.80</td>\n","      <td>1.57</td>\n","      <td>0.02</td>\n","      <td>0.04</td>\n","    </tr>\n","    <tr>\n","      <th>OrthogonalMatchingPursuit</th>\n","      <td>-0.82</td>\n","      <td>-0.82</td>\n","      <td>1.58</td>\n","      <td>0.01</td>\n","      <td>-0.05</td>\n","    </tr>\n","    <tr>\n","      <th>NuSVR</th>\n","      <td>-0.90</td>\n","      <td>-0.90</td>\n","      <td>1.62</td>\n","      <td>0.26</td>\n","      <td>-0.05</td>\n","    </tr>\n","    <tr>\n","      <th>MLPRegressor</th>\n","      <td>-0.96</td>\n","      <td>-0.96</td>\n","      <td>1.64</td>\n","      <td>1.82</td>\n","      <td>-0.05</td>\n","    </tr>\n","    <tr>\n","      <th>SVR</th>\n","      <td>-1.17</td>\n","      <td>-1.17</td>\n","      <td>1.72</td>\n","      <td>0.36</td>\n","      <td>-0.06</td>\n","    </tr>\n","    <tr>\n","      <th>GradientBoostingRegressor</th>\n","      <td>-1.18</td>\n","      <td>-1.18</td>\n","      <td>1.73</td>\n","      <td>0.20</td>\n","      <td>-0.09</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestRegressor</th>\n","      <td>-1.21</td>\n","      <td>-1.20</td>\n","      <td>1.74</td>\n","      <td>0.56</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>HistGradientBoostingRegressor</th>\n","      <td>-1.23</td>\n","      <td>-1.23</td>\n","      <td>1.75</td>\n","      <td>1.37</td>\n","      <td>-0.07</td>\n","    </tr>\n","    <tr>\n","      <th>LGBMRegressor</th>\n","      <td>-1.23</td>\n","      <td>-1.23</td>\n","      <td>1.75</td>\n","      <td>0.21</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsRegressor</th>\n","      <td>-1.24</td>\n","      <td>-1.24</td>\n","      <td>1.75</td>\n","      <td>0.02</td>\n","      <td>-0.07</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesRegressor</th>\n","      <td>-1.27</td>\n","      <td>-1.26</td>\n","      <td>1.76</td>\n","      <td>0.34</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>BaggingRegressor</th>\n","      <td>-1.29</td>\n","      <td>-1.29</td>\n","      <td>1.77</td>\n","      <td>0.07</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>XGBRegressor</th>\n","      <td>-1.38</td>\n","      <td>-1.37</td>\n","      <td>1.80</td>\n","      <td>0.31</td>\n","      <td>-0.09</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeRegressor</th>\n","      <td>-1.91</td>\n","      <td>-1.90</td>\n","      <td>2.00</td>\n","      <td>0.02</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeRegressor</th>\n","      <td>-1.95</td>\n","      <td>-1.94</td>\n","      <td>2.01</td>\n","      <td>0.02</td>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>PassiveAggressiveRegressor</th>\n","      <td>-2.26</td>\n","      <td>-2.25</td>\n","      <td>2.11</td>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","    </tr>\n","    <tr>\n","      <th>KernelRidge</th>\n","      <td>-8.89</td>\n","      <td>-8.87</td>\n","      <td>3.68</td>\n","      <td>0.20</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>GaussianProcessRegressor</th>\n","      <td>-1307114.74</td>\n","      <td>-1304793.87</td>\n","      <td>1338.54</td>\n","      <td>0.53</td>\n","      <td>-0.03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Adjusted R-Squared   R-Squared    RMSE  \\\n","Model                                                                   \n","Lasso                                       -0.02       -0.02    1.18   \n","LassoLars                                   -0.02       -0.02    1.18   \n","DummyRegressor                              -0.02       -0.02    1.18   \n","ElasticNet                                  -0.10       -0.10    1.23   \n","TweedieRegressor                            -0.42       -0.41    1.39   \n","PoissonRegressor                            -0.57       -0.57    1.47   \n","SGDRegressor                                -0.66       -0.65    1.51   \n","RANSACRegressor                             -0.69       -0.69    1.52   \n","AdaBoostRegressor                           -0.74       -0.74    1.55   \n","ElasticNetCV                                -0.77       -0.76    1.56   \n","LinearSVR                                   -0.77       -0.76    1.56   \n","LassoCV                                     -0.77       -0.77    1.56   \n","Ridge                                       -0.78       -0.77    1.56   \n","BayesianRidge                               -0.78       -0.78    1.56   \n","RidgeCV                                     -0.78       -0.78    1.56   \n","TransformedTargetRegressor                  -0.78       -0.78    1.56   \n","LinearRegression                            -0.78       -0.78    1.56   \n","LassoLarsIC                                 -0.78       -0.78    1.56   \n","LassoLarsCV                                 -0.78       -0.78    1.56   \n","LarsCV                                      -0.78       -0.78    1.56   \n","Lars                                        -0.78       -0.78    1.56   \n","OrthogonalMatchingPursuitCV                 -0.78       -0.78    1.56   \n","HuberRegressor                              -0.80       -0.80    1.57   \n","OrthogonalMatchingPursuit                   -0.82       -0.82    1.58   \n","NuSVR                                       -0.90       -0.90    1.62   \n","MLPRegressor                                -0.96       -0.96    1.64   \n","SVR                                         -1.17       -1.17    1.72   \n","GradientBoostingRegressor                   -1.18       -1.18    1.73   \n","RandomForestRegressor                       -1.21       -1.20    1.74   \n","HistGradientBoostingRegressor               -1.23       -1.23    1.75   \n","LGBMRegressor                               -1.23       -1.23    1.75   \n","KNeighborsRegressor                         -1.24       -1.24    1.75   \n","ExtraTreesRegressor                         -1.27       -1.26    1.76   \n","BaggingRegressor                            -1.29       -1.29    1.77   \n","XGBRegressor                                -1.38       -1.37    1.80   \n","DecisionTreeRegressor                       -1.91       -1.90    2.00   \n","ExtraTreeRegressor                          -1.95       -1.94    2.01   \n","PassiveAggressiveRegressor                  -2.26       -2.25    2.11   \n","KernelRidge                                 -8.89       -8.87    3.68   \n","GaussianProcessRegressor              -1307114.74 -1304793.87 1338.54   \n","\n","                               Time Taken  pearsonr_scorer  \n","Model                                                       \n","Lasso                                0.02              NaN  \n","LassoLars                            0.01              NaN  \n","DummyRegressor                       0.01              NaN  \n","ElasticNet                           0.02            -0.05  \n","TweedieRegressor                     0.29            -0.07  \n","PoissonRegressor                     0.45            -0.05  \n","SGDRegressor                         0.01             0.02  \n","RANSACRegressor                      0.09             0.06  \n","AdaBoostRegressor                    0.07            -0.06  \n","ElasticNetCV                         0.10             0.03  \n","LinearSVR                            0.02             0.04  \n","LassoCV                              0.09             0.03  \n","Ridge                                0.01             0.03  \n","BayesianRidge                        0.01             0.03  \n","RidgeCV                              0.01             0.03  \n","TransformedTargetRegressor           0.01             0.03  \n","LinearRegression                     0.01             0.03  \n","LassoLarsIC                          0.02             0.03  \n","LassoLarsCV                          0.03             0.03  \n","LarsCV                               0.02             0.03  \n","Lars                                 0.01             0.03  \n","OrthogonalMatchingPursuitCV          0.01             0.03  \n","HuberRegressor                       0.02             0.04  \n","OrthogonalMatchingPursuit            0.01            -0.05  \n","NuSVR                                0.26            -0.05  \n","MLPRegressor                         1.82            -0.05  \n","SVR                                  0.36            -0.06  \n","GradientBoostingRegressor            0.20            -0.09  \n","RandomForestRegressor                0.56            -0.08  \n","HistGradientBoostingRegressor        1.37            -0.07  \n","LGBMRegressor                        0.21            -0.08  \n","KNeighborsRegressor                  0.02            -0.07  \n","ExtraTreesRegressor                  0.34            -0.08  \n","BaggingRegressor                     0.07            -0.08  \n","XGBRegressor                         0.31            -0.09  \n","DecisionTreeRegressor                0.02            -0.08  \n","ExtraTreeRegressor                   0.02            -0.08  \n","PassiveAggressiveRegressor           0.01            -0.01  \n","KernelRidge                          0.20             0.03  \n","GaussianProcessRegressor             0.53            -0.03  "]},"execution_count":157,"metadata":{},"output_type":"execute_result"}],"source":["regresion_models"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"data":{"text/plain":["[[nan, 'LassoLars'],\n"," [nan, 'Lasso'],\n"," [nan, 'DummyRegressor'],\n"," [0.05721888503847159, 'RANSACRegressor'],\n"," [0.04100837525433105, 'HuberRegressor'],\n"," [0.03998623957091646, 'LinearSVR'],\n"," [0.03327424833609833, 'OrthogonalMatchingPursuitCV'],\n"," [0.033274248336098065, 'LassoLarsIC'],\n"," [0.033274248336098065, 'LassoLarsCV'],\n"," [0.033274248336098065, 'LarsCV'],\n"," [0.033274248336098065, 'Lars'],\n"," [0.03327424833609599, 'TransformedTargetRegressor'],\n"," [0.03327424833609599, 'LinearRegression'],\n"," [0.033115770655412435, 'RidgeCV'],\n"," [0.032348320400756754, 'BayesianRidge'],\n"," [0.031736644824700455, 'KernelRidge'],\n"," [0.03173664482467233, 'Ridge'],\n"," [0.03143706912083802, 'LassoCV'],\n"," [0.02863492676706457, 'ElasticNetCV'],\n"," [0.016753109501593248, 'SGDRegressor'],\n"," [-0.005543871375680092, 'PassiveAggressiveRegressor'],\n"," [-0.026435763448017128, 'GaussianProcessRegressor'],\n"," [-0.0513530358003796, 'OrthogonalMatchingPursuit'],\n"," [-0.051353035800379615, 'ElasticNet'],\n"," [-0.05140853373358763, 'PoissonRegressor'],\n"," [-0.05313905564012349, 'MLPRegressor'],\n"," [-0.05493927122631131, 'NuSVR'],\n"," [-0.06335532499268984, 'SVR'],\n"," [-0.0634596333397755, 'AdaBoostRegressor'],\n"," [-0.06889333626201584, 'KNeighborsRegressor'],\n"," [-0.07197965343307115, 'TweedieRegressor'],\n"," [-0.0734295568354714, 'HistGradientBoostingRegressor'],\n"," [-0.07355814372638086, 'QuantileRegressor'],\n"," [-0.07506677277338361, 'LGBMRegressor'],\n"," [-0.07662911200395438, 'RandomForestRegressor'],\n"," [-0.07673337392739445, 'DecisionTreeRegressor'],\n"," [-0.07823878108677704, 'ExtraTreeRegressor'],\n"," [-0.07987543333707416, 'BaggingRegressor'],\n"," [-0.08056254282695005, 'ExtraTreesRegressor'],\n"," [-0.09148560276598611, 'XGBRegressor'],\n"," [-0.09260760820621453, 'GradientBoostingRegressor']]"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["sorted([ [pearsonr(regresion_predictions[model[0]], y_test)[0], model[0]] for model in regresion_models.iterrows() ], reverse=True)"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Adjusted R-Squared</th>\n","      <th>R-Squared</th>\n","      <th>RMSE</th>\n","      <th>Time Taken</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Lasso</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.04</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLars</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>DummyRegressor</th>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>1.18</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNet</th>\n","      <td>-0.10</td>\n","      <td>-0.10</td>\n","      <td>1.23</td>\n","      <td>0.05</td>\n","    </tr>\n","    <tr>\n","      <th>TweedieRegressor</th>\n","      <td>-0.42</td>\n","      <td>-0.41</td>\n","      <td>1.39</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>PoissonRegressor</th>\n","      <td>-0.57</td>\n","      <td>-0.57</td>\n","      <td>1.47</td>\n","      <td>0.47</td>\n","    </tr>\n","    <tr>\n","      <th>SGDRegressor</th>\n","      <td>-0.66</td>\n","      <td>-0.65</td>\n","      <td>1.51</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>RANSACRegressor</th>\n","      <td>-0.69</td>\n","      <td>-0.69</td>\n","      <td>1.52</td>\n","      <td>0.14</td>\n","    </tr>\n","    <tr>\n","      <th>AdaBoostRegressor</th>\n","      <td>-0.74</td>\n","      <td>-0.74</td>\n","      <td>1.55</td>\n","      <td>0.05</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNetCV</th>\n","      <td>-0.77</td>\n","      <td>-0.76</td>\n","      <td>1.56</td>\n","      <td>0.09</td>\n","    </tr>\n","    <tr>\n","      <th>LinearSVR</th>\n","      <td>-0.77</td>\n","      <td>-0.76</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoCV</th>\n","      <td>-0.77</td>\n","      <td>-0.77</td>\n","      <td>1.56</td>\n","      <td>0.09</td>\n","    </tr>\n","    <tr>\n","      <th>Ridge</th>\n","      <td>-0.78</td>\n","      <td>-0.77</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>BayesianRidge</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>RidgeCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>TransformedTargetRegressor</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LinearRegression</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsIC</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LarsCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>Lars</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>OrthogonalMatchingPursuitCV</th>\n","      <td>-0.78</td>\n","      <td>-0.78</td>\n","      <td>1.56</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>HuberRegressor</th>\n","      <td>-0.80</td>\n","      <td>-0.80</td>\n","      <td>1.57</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>OrthogonalMatchingPursuit</th>\n","      <td>-0.82</td>\n","      <td>-0.82</td>\n","      <td>1.58</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>NuSVR</th>\n","      <td>-0.90</td>\n","      <td>-0.90</td>\n","      <td>1.62</td>\n","      <td>0.26</td>\n","    </tr>\n","    <tr>\n","      <th>MLPRegressor</th>\n","      <td>-0.96</td>\n","      <td>-0.96</td>\n","      <td>1.64</td>\n","      <td>1.61</td>\n","    </tr>\n","    <tr>\n","      <th>SVR</th>\n","      <td>-1.17</td>\n","      <td>-1.17</td>\n","      <td>1.72</td>\n","      <td>0.36</td>\n","    </tr>\n","    <tr>\n","      <th>GradientBoostingRegressor</th>\n","      <td>-1.18</td>\n","      <td>-1.18</td>\n","      <td>1.73</td>\n","      <td>0.20</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestRegressor</th>\n","      <td>-1.21</td>\n","      <td>-1.20</td>\n","      <td>1.74</td>\n","      <td>0.57</td>\n","    </tr>\n","    <tr>\n","      <th>HistGradientBoostingRegressor</th>\n","      <td>-1.23</td>\n","      <td>-1.23</td>\n","      <td>1.75</td>\n","      <td>0.55</td>\n","    </tr>\n","    <tr>\n","      <th>LGBMRegressor</th>\n","      <td>-1.23</td>\n","      <td>-1.23</td>\n","      <td>1.75</td>\n","      <td>0.13</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsRegressor</th>\n","      <td>-1.24</td>\n","      <td>-1.24</td>\n","      <td>1.75</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesRegressor</th>\n","      <td>-1.27</td>\n","      <td>-1.26</td>\n","      <td>1.76</td>\n","      <td>0.33</td>\n","    </tr>\n","    <tr>\n","      <th>BaggingRegressor</th>\n","      <td>-1.29</td>\n","      <td>-1.29</td>\n","      <td>1.77</td>\n","      <td>0.07</td>\n","    </tr>\n","    <tr>\n","      <th>XGBRegressor</th>\n","      <td>-1.38</td>\n","      <td>-1.37</td>\n","      <td>1.80</td>\n","      <td>0.30</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeRegressor</th>\n","      <td>-1.91</td>\n","      <td>-1.90</td>\n","      <td>2.00</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeRegressor</th>\n","      <td>-1.95</td>\n","      <td>-1.94</td>\n","      <td>2.01</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>PassiveAggressiveRegressor</th>\n","      <td>-2.26</td>\n","      <td>-2.25</td>\n","      <td>2.11</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>KernelRidge</th>\n","      <td>-8.89</td>\n","      <td>-8.87</td>\n","      <td>3.68</td>\n","      <td>0.19</td>\n","    </tr>\n","    <tr>\n","      <th>GaussianProcessRegressor</th>\n","      <td>-1307114.74</td>\n","      <td>-1304793.87</td>\n","      <td>1338.54</td>\n","      <td>0.51</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Adjusted R-Squared   R-Squared    RMSE  \\\n","Model                                                                   \n","Lasso                                       -0.02       -0.02    1.18   \n","LassoLars                                   -0.02       -0.02    1.18   \n","DummyRegressor                              -0.02       -0.02    1.18   \n","ElasticNet                                  -0.10       -0.10    1.23   \n","TweedieRegressor                            -0.42       -0.41    1.39   \n","PoissonRegressor                            -0.57       -0.57    1.47   \n","SGDRegressor                                -0.66       -0.65    1.51   \n","RANSACRegressor                             -0.69       -0.69    1.52   \n","AdaBoostRegressor                           -0.74       -0.74    1.55   \n","ElasticNetCV                                -0.77       -0.76    1.56   \n","LinearSVR                                   -0.77       -0.76    1.56   \n","LassoCV                                     -0.77       -0.77    1.56   \n","Ridge                                       -0.78       -0.77    1.56   \n","BayesianRidge                               -0.78       -0.78    1.56   \n","RidgeCV                                     -0.78       -0.78    1.56   \n","TransformedTargetRegressor                  -0.78       -0.78    1.56   \n","LinearRegression                            -0.78       -0.78    1.56   \n","LassoLarsIC                                 -0.78       -0.78    1.56   \n","LassoLarsCV                                 -0.78       -0.78    1.56   \n","LarsCV                                      -0.78       -0.78    1.56   \n","Lars                                        -0.78       -0.78    1.56   \n","OrthogonalMatchingPursuitCV                 -0.78       -0.78    1.56   \n","HuberRegressor                              -0.80       -0.80    1.57   \n","OrthogonalMatchingPursuit                   -0.82       -0.82    1.58   \n","NuSVR                                       -0.90       -0.90    1.62   \n","MLPRegressor                                -0.96       -0.96    1.64   \n","SVR                                         -1.17       -1.17    1.72   \n","GradientBoostingRegressor                   -1.18       -1.18    1.73   \n","RandomForestRegressor                       -1.21       -1.20    1.74   \n","HistGradientBoostingRegressor               -1.23       -1.23    1.75   \n","LGBMRegressor                               -1.23       -1.23    1.75   \n","KNeighborsRegressor                         -1.24       -1.24    1.75   \n","ExtraTreesRegressor                         -1.27       -1.26    1.76   \n","BaggingRegressor                            -1.29       -1.29    1.77   \n","XGBRegressor                                -1.38       -1.37    1.80   \n","DecisionTreeRegressor                       -1.91       -1.90    2.00   \n","ExtraTreeRegressor                          -1.95       -1.94    2.01   \n","PassiveAggressiveRegressor                  -2.26       -2.25    2.11   \n","KernelRidge                                 -8.89       -8.87    3.68   \n","GaussianProcessRegressor              -1307114.74 -1304793.87 1338.54   \n","\n","                               Time Taken  \n","Model                                      \n","Lasso                                0.04  \n","LassoLars                            0.01  \n","DummyRegressor                       0.01  \n","ElasticNet                           0.05  \n","TweedieRegressor                     0.25  \n","PoissonRegressor                     0.47  \n","SGDRegressor                         0.01  \n","RANSACRegressor                      0.14  \n","AdaBoostRegressor                    0.05  \n","ElasticNetCV                         0.09  \n","LinearSVR                            0.01  \n","LassoCV                              0.09  \n","Ridge                                0.01  \n","BayesianRidge                        0.01  \n","RidgeCV                              0.01  \n","TransformedTargetRegressor           0.01  \n","LinearRegression                     0.01  \n","LassoLarsIC                          0.01  \n","LassoLarsCV                          0.01  \n","LarsCV                               0.01  \n","Lars                                 0.01  \n","OrthogonalMatchingPursuitCV          0.01  \n","HuberRegressor                       0.02  \n","OrthogonalMatchingPursuit            0.01  \n","NuSVR                                0.26  \n","MLPRegressor                         1.61  \n","SVR                                  0.36  \n","GradientBoostingRegressor            0.20  \n","RandomForestRegressor                0.57  \n","HistGradientBoostingRegressor        0.55  \n","LGBMRegressor                        0.13  \n","KNeighborsRegressor                  0.02  \n","ExtraTreesRegressor                  0.33  \n","BaggingRegressor                     0.07  \n","XGBRegressor                         0.30  \n","DecisionTreeRegressor                0.02  \n","ExtraTreeRegressor                   0.01  \n","PassiveAggressiveRegressor           0.01  \n","KernelRidge                          0.19  \n","GaussianProcessRegressor             0.51  "]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["regresion_models"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients: \n"," [-0.32420085 -1.17168017  3.79771734]\n","Mean squared error: 1.53\n","Variance score: -0.53\n"]},{"ename":"ValueError","evalue":"x and y must be the same size","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [89], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mVariance score: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m r2_score(y_test_norm, y_pred))\n\u001b[1;32m     13\u001b[0m \u001b[39m# Plot outputs\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(X_test_features\u001b[39m.\u001b[39;49mT, y_test_norm,  color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblack\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m plt\u001b[39m.\u001b[39mplot(X_test_features, y_pred, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     16\u001b[0m plt\u001b[39m.\u001b[39mxticks(())\n","File \u001b[0;32m~/IHLT/ihlt/lib/python3.10/site-packages/matplotlib/pyplot.py:2817\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2812\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[1;32m   2813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m   2814\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2815\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2816\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2817\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[1;32m   2818\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   2819\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[1;32m   2820\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[1;32m   2821\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2822\u001b[0m     sci(__ret)\n\u001b[1;32m   2823\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n","File \u001b[0;32m~/IHLT/ihlt/lib/python3.10/site-packages/matplotlib/__init__.py:1414\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1413\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1416\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1417\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1418\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n","File \u001b[0;32m~/IHLT/ihlt/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4368\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4366\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[1;32m   4367\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[0;32m-> 4368\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4370\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4371\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m rcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[1;32m   4372\u001b[0m          rcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: x and y must be the same size"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["regr = linear_model.LinearRegression()\n","# Train the model using the training sets\n","regr.fit(X_train_features.T,y_train_norm )\n","# Make predictions using the testing set\n","y_pred = regr.predict(X_test_features.T)\n","# The coefficients\n","print('Coefficients: \\n', regr.coef_)\n","# The mean squared error\n","print(\"Mean squared error: %.2f\"\n","        % mean_squared_error(y_test_norm, y_pred))\n","# Explained variance score: 1 is perfect prediction \n","print('Variance score: %.2f' % r2_score(y_test_norm, y_pred))\n","# Plot outputs\n","plt.scatter(X_test_features.T, y_test_norm,  color='black')\n","plt.plot(X_test_features, y_pred, color='blue', linewidth=3)\n","plt.xticks(())\n","plt.yticks(())\n","plt.show()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients: \n"," [938.23786125]\n","Mean squared error: 2548.07\n","Variance score: 0.47\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Import a dataset  from sklearn\n","from matplotlib import pyplot as plt\n","#import mean_squared_error from sklearn\n","from sklearn.metrics import mean_squared_error\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","# import r2_score from sklearn\n","from sklearn.metrics import r2_score\n","# Load the diabetes dataset\n","diabetes = datasets.load_diabetes()\n","# Use only one feature\n","diabetes_X = diabetes.data[:, np.newaxis, 2]\n","# Split the data into training/testing sets\n","diabetes_X_train = diabetes_X[:-20]\n","diabetes_X_test = diabetes_X[-20:]\n","# Split the targets into training/testing sets\n","diabetes_y_train = diabetes.target[:-20]\n","diabetes_y_test = diabetes.target[-20:]\n","# Create linear regression object\n","regr = linear_model.LinearRegression()\n","# Train the model using the training sets\n","regr.fit(diabetes_X_train, diabetes_y_train)\n","# Make predictions using the testing set\n","diabetes_y_pred = regr.predict(diabetes_X_test)\n","# The coefficients\n","print('Coefficients: \\n', regr.coef_)\n","# The mean squared error\n","print(\"Mean squared error: %.2f\"\n","        % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n","# Explained variance score: 1 is perfect prediction \n","print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n","# Plot outputs\n","plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n","plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n","plt.xticks(())\n","plt.yticks(())\n","plt.show()\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 42/42 [00:05<00:00,  7.50it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Adjusted R-Squared</th>\n","      <th>R-Squared</th>\n","      <th>RMSE</th>\n","      <th>Time Taken</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>PassiveAggressiveRegressor</th>\n","      <td>0.51</td>\n","      <td>0.54</td>\n","      <td>47.22</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>RANSACRegressor</th>\n","      <td>0.50</td>\n","      <td>0.52</td>\n","      <td>47.96</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>PoissonRegressor</th>\n","      <td>0.47</td>\n","      <td>0.50</td>\n","      <td>49.11</td>\n","      <td>0.13</td>\n","    </tr>\n","    <tr>\n","      <th>HuberRegressor</th>\n","      <td>0.47</td>\n","      <td>0.50</td>\n","      <td>49.33</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LarsCV</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>OrthogonalMatchingPursuit</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LinearRegression</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsIC</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLarsCV</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>TransformedTargetRegressor</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>Lars</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.48</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoCV</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.49</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>RidgeCV</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.50</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>Ridge</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.50</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>SGDRegressor</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.51</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>BayesianRidge</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.53</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>Lasso</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.72</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LassoLars</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.72</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>LinearSVR</th>\n","      <td>0.44</td>\n","      <td>0.47</td>\n","      <td>50.81</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNetCV</th>\n","      <td>0.43</td>\n","      <td>0.46</td>\n","      <td>50.97</td>\n","      <td>0.05</td>\n","    </tr>\n","    <tr>\n","      <th>GaussianProcessRegressor</th>\n","      <td>0.42</td>\n","      <td>0.45</td>\n","      <td>51.45</td>\n","      <td>0.04</td>\n","    </tr>\n","    <tr>\n","      <th>HistGradientBoostingRegressor</th>\n","      <td>0.38</td>\n","      <td>0.41</td>\n","      <td>53.44</td>\n","      <td>0.41</td>\n","    </tr>\n","    <tr>\n","      <th>GradientBoostingRegressor</th>\n","      <td>0.36</td>\n","      <td>0.39</td>\n","      <td>54.11</td>\n","      <td>0.07</td>\n","    </tr>\n","    <tr>\n","      <th>LGBMRegressor</th>\n","      <td>0.34</td>\n","      <td>0.38</td>\n","      <td>54.89</td>\n","      <td>0.08</td>\n","    </tr>\n","    <tr>\n","      <th>ElasticNet</th>\n","      <td>0.31</td>\n","      <td>0.35</td>\n","      <td>56.02</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>AdaBoostRegressor</th>\n","      <td>0.30</td>\n","      <td>0.34</td>\n","      <td>56.63</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>SVR</th>\n","      <td>0.29</td>\n","      <td>0.33</td>\n","      <td>57.03</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>GammaRegressor</th>\n","      <td>0.25</td>\n","      <td>0.29</td>\n","      <td>58.60</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>TweedieRegressor</th>\n","      <td>0.22</td>\n","      <td>0.26</td>\n","      <td>59.75</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsRegressor</th>\n","      <td>0.22</td>\n","      <td>0.26</td>\n","      <td>59.81</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>NuSVR</th>\n","      <td>0.15</td>\n","      <td>0.19</td>\n","      <td>62.51</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestRegressor</th>\n","      <td>0.01</td>\n","      <td>0.07</td>\n","      <td>67.20</td>\n","      <td>0.20</td>\n","    </tr>\n","    <tr>\n","      <th>BaggingRegressor</th>\n","      <td>-0.02</td>\n","      <td>0.03</td>\n","      <td>68.48</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>QuantileRegressor</th>\n","      <td>-0.11</td>\n","      <td>-0.05</td>\n","      <td>71.13</td>\n","      <td>3.49</td>\n","    </tr>\n","    <tr>\n","      <th>DummyRegressor</th>\n","      <td>-0.22</td>\n","      <td>-0.15</td>\n","      <td>74.63</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesRegressor</th>\n","      <td>-0.27</td>\n","      <td>-0.20</td>\n","      <td>76.19</td>\n","      <td>0.10</td>\n","    </tr>\n","    <tr>\n","      <th>XGBRegressor</th>\n","      <td>-0.29</td>\n","      <td>-0.22</td>\n","      <td>76.89</td>\n","      <td>0.08</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeRegressor</th>\n","      <td>-0.30</td>\n","      <td>-0.23</td>\n","      <td>77.04</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeRegressor</th>\n","      <td>-0.30</td>\n","      <td>-0.23</td>\n","      <td>77.04</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>MLPRegressor</th>\n","      <td>-0.95</td>\n","      <td>-0.85</td>\n","      <td>94.45</td>\n","      <td>0.47</td>\n","    </tr>\n","    <tr>\n","      <th>KernelRidge</th>\n","      <td>-3.53</td>\n","      <td>-3.29</td>\n","      <td>144.01</td>\n","      <td>0.01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Adjusted R-Squared  R-Squared   RMSE  \\\n","Model                                                                 \n","PassiveAggressiveRegressor                   0.51       0.54  47.22   \n","RANSACRegressor                              0.50       0.52  47.96   \n","PoissonRegressor                             0.47       0.50  49.11   \n","HuberRegressor                               0.47       0.50  49.33   \n","LarsCV                                       0.44       0.47  50.48   \n","OrthogonalMatchingPursuit                    0.44       0.47  50.48   \n","LinearRegression                             0.44       0.47  50.48   \n","LassoLarsIC                                  0.44       0.47  50.48   \n","LassoLarsCV                                  0.44       0.47  50.48   \n","TransformedTargetRegressor                   0.44       0.47  50.48   \n","Lars                                         0.44       0.47  50.48   \n","LassoCV                                      0.44       0.47  50.49   \n","RidgeCV                                      0.44       0.47  50.50   \n","Ridge                                        0.44       0.47  50.50   \n","SGDRegressor                                 0.44       0.47  50.51   \n","BayesianRidge                                0.44       0.47  50.53   \n","Lasso                                        0.44       0.47  50.72   \n","LassoLars                                    0.44       0.47  50.72   \n","LinearSVR                                    0.44       0.47  50.81   \n","ElasticNetCV                                 0.43       0.46  50.97   \n","GaussianProcessRegressor                     0.42       0.45  51.45   \n","HistGradientBoostingRegressor                0.38       0.41  53.44   \n","GradientBoostingRegressor                    0.36       0.39  54.11   \n","LGBMRegressor                                0.34       0.38  54.89   \n","ElasticNet                                   0.31       0.35  56.02   \n","AdaBoostRegressor                            0.30       0.34  56.63   \n","SVR                                          0.29       0.33  57.03   \n","GammaRegressor                               0.25       0.29  58.60   \n","TweedieRegressor                             0.22       0.26  59.75   \n","KNeighborsRegressor                          0.22       0.26  59.81   \n","NuSVR                                        0.15       0.19  62.51   \n","RandomForestRegressor                        0.01       0.07  67.20   \n","BaggingRegressor                            -0.02       0.03  68.48   \n","QuantileRegressor                           -0.11      -0.05  71.13   \n","DummyRegressor                              -0.22      -0.15  74.63   \n","ExtraTreesRegressor                         -0.27      -0.20  76.19   \n","XGBRegressor                                -0.29      -0.22  76.89   \n","ExtraTreeRegressor                          -0.30      -0.23  77.04   \n","DecisionTreeRegressor                       -0.30      -0.23  77.04   \n","MLPRegressor                                -0.95      -0.85  94.45   \n","KernelRidge                                 -3.53      -3.29 144.01   \n","\n","                               Time Taken  \n","Model                                      \n","PassiveAggressiveRegressor           0.01  \n","RANSACRegressor                      0.06  \n","PoissonRegressor                     0.13  \n","HuberRegressor                       0.01  \n","LarsCV                               0.01  \n","OrthogonalMatchingPursuit            0.01  \n","LinearRegression                     0.01  \n","LassoLarsIC                          0.01  \n","LassoLarsCV                          0.02  \n","TransformedTargetRegressor           0.01  \n","Lars                                 0.01  \n","LassoCV                              0.06  \n","RidgeCV                              0.01  \n","Ridge                                0.01  \n","SGDRegressor                         0.01  \n","BayesianRidge                        0.01  \n","Lasso                                0.01  \n","LassoLars                            0.01  \n","LinearSVR                            0.01  \n","ElasticNetCV                         0.05  \n","GaussianProcessRegressor             0.04  \n","HistGradientBoostingRegressor        0.41  \n","GradientBoostingRegressor            0.07  \n","LGBMRegressor                        0.08  \n","ElasticNet                           0.01  \n","AdaBoostRegressor                    0.03  \n","SVR                                  0.02  \n","GammaRegressor                       0.01  \n","TweedieRegressor                     0.02  \n","KNeighborsRegressor                  0.01  \n","NuSVR                                0.02  \n","RandomForestRegressor                0.20  \n","BaggingRegressor                     0.02  \n","QuantileRegressor                    3.49  \n","DummyRegressor                       0.01  \n","ExtraTreesRegressor                  0.10  \n","XGBRegressor                         0.08  \n","ExtraTreeRegressor                   0.01  \n","DecisionTreeRegressor                0.01  \n","MLPRegressor                         0.47  \n","KernelRidge                          0.01  "]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# use lazypredict to predict the model\n","from lazypredict.Supervised import LazyRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","# fit all models\n","reg = LazyRegressor(predictions=True)\n","regresion_models, regresion_predictions = reg.fit(diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test) \n","regresion_models\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["(422, 1)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["diabetes_X_train.shape"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.06169621],\n","       [-0.05147406],\n","       [ 0.04445121],\n","       [-0.01159501],\n","       [-0.03638469],\n","       [-0.04069594],\n","       [-0.04716281],\n","       [-0.00189471],\n","       [ 0.06169621],\n","       [ 0.03906215],\n","       [-0.08380842],\n","       [ 0.01750591],\n","       [-0.02884001],\n","       [-0.00189471],\n","       [-0.02560657],\n","       [-0.01806189],\n","       [ 0.04229559],\n","       [ 0.01211685],\n","       [-0.0105172 ],\n","       [-0.01806189],\n","       [-0.05686312],\n","       [-0.02237314],\n","       [-0.00405033],\n","       [ 0.06061839],\n","       [ 0.03582872],\n","       [-0.01267283],\n","       [-0.07734155],\n","       [ 0.05954058],\n","       [-0.02129532],\n","       [-0.00620595],\n","       [ 0.04445121],\n","       [-0.06548562],\n","       [ 0.12528712],\n","       [-0.05039625],\n","       [-0.06332999],\n","       [-0.03099563],\n","       [ 0.02289497],\n","       [ 0.01103904],\n","       [ 0.07139652],\n","       [ 0.01427248],\n","       [-0.00836158],\n","       [-0.06764124],\n","       [-0.0105172 ],\n","       [-0.02345095],\n","       [ 0.06816308],\n","       [-0.03530688],\n","       [-0.01159501],\n","       [-0.0730303 ],\n","       [-0.04177375],\n","       [ 0.01427248],\n","       [-0.00728377],\n","       [ 0.0164281 ],\n","       [-0.00943939],\n","       [-0.01590626],\n","       [ 0.0250506 ],\n","       [-0.04931844],\n","       [ 0.04121778],\n","       [-0.06332999],\n","       [-0.06440781],\n","       [-0.02560657],\n","       [-0.00405033],\n","       [ 0.00457217],\n","       [-0.00728377],\n","       [-0.0374625 ],\n","       [-0.02560657],\n","       [-0.02452876],\n","       [-0.01806189],\n","       [-0.01482845],\n","       [-0.02991782],\n","       [-0.046085  ],\n","       [-0.06979687],\n","       [ 0.03367309],\n","       [-0.00405033],\n","       [-0.02021751],\n","       [ 0.00241654],\n","       [-0.03099563],\n","       [ 0.02828403],\n","       [-0.03638469],\n","       [-0.05794093],\n","       [-0.0374625 ],\n","       [ 0.01211685],\n","       [-0.02237314],\n","       [-0.03530688],\n","       [ 0.00996123],\n","       [-0.03961813],\n","       [ 0.07139652],\n","       [-0.07518593],\n","       [-0.00620595],\n","       [-0.04069594],\n","       [-0.04824063],\n","       [-0.02560657],\n","       [ 0.0519959 ],\n","       [ 0.00457217],\n","       [-0.06440781],\n","       [-0.01698407],\n","       [-0.05794093],\n","       [ 0.00996123],\n","       [ 0.08864151],\n","       [-0.00512814],\n","       [-0.06440781],\n","       [ 0.01750591],\n","       [-0.04500719],\n","       [ 0.02828403],\n","       [ 0.04121778],\n","       [ 0.06492964],\n","       [-0.03207344],\n","       [-0.07626374],\n","       [ 0.04984027],\n","       [ 0.04552903],\n","       [-0.00943939],\n","       [-0.03207344],\n","       [ 0.00457217],\n","       [ 0.02073935],\n","       [ 0.01427248],\n","       [ 0.11019775],\n","       [ 0.00133873],\n","       [ 0.05846277],\n","       [-0.02129532],\n","       [-0.0105172 ],\n","       [-0.04716281],\n","       [ 0.00457217],\n","       [ 0.01750591],\n","       [ 0.08109682],\n","       [ 0.0347509 ],\n","       [ 0.02397278],\n","       [-0.00836158],\n","       [-0.06117437],\n","       [-0.00189471],\n","       [-0.06225218],\n","       [ 0.0164281 ],\n","       [ 0.09618619],\n","       [-0.06979687],\n","       [-0.02129532],\n","       [-0.05362969],\n","       [ 0.0433734 ],\n","       [ 0.05630715],\n","       [-0.0816528 ],\n","       [ 0.04984027],\n","       [ 0.11127556],\n","       [ 0.06169621],\n","       [ 0.01427248],\n","       [ 0.04768465],\n","       [ 0.01211685],\n","       [ 0.00564998],\n","       [ 0.04660684],\n","       [ 0.12852056],\n","       [ 0.05954058],\n","       [ 0.09295276],\n","       [ 0.01535029],\n","       [-0.00512814],\n","       [ 0.0703187 ],\n","       [-0.00405033],\n","       [-0.00081689],\n","       [-0.04392938],\n","       [ 0.02073935],\n","       [ 0.06061839],\n","       [-0.0105172 ],\n","       [-0.03315126],\n","       [-0.06548562],\n","       [ 0.0433734 ],\n","       [-0.06225218],\n","       [ 0.06385183],\n","       [ 0.03043966],\n","       [ 0.07247433],\n","       [-0.0191397 ],\n","       [-0.06656343],\n","       [-0.06009656],\n","       [ 0.06924089],\n","       [ 0.05954058],\n","       [-0.02668438],\n","       [-0.02021751],\n","       [-0.046085  ],\n","       [ 0.07139652],\n","       [-0.07949718],\n","       [ 0.00996123],\n","       [-0.03854032],\n","       [ 0.01966154],\n","       [ 0.02720622],\n","       [-0.00836158],\n","       [-0.01590626],\n","       [ 0.00457217],\n","       [-0.04285156],\n","       [ 0.00564998],\n","       [-0.03530688],\n","       [ 0.02397278],\n","       [-0.01806189],\n","       [ 0.04229559],\n","       [-0.0547075 ],\n","       [-0.00297252],\n","       [-0.06656343],\n","       [-0.01267283],\n","       [-0.04177375],\n","       [-0.03099563],\n","       [-0.00512814],\n","       [-0.05901875],\n","       [ 0.0250506 ],\n","       [-0.046085  ],\n","       [ 0.00349435],\n","       [ 0.05415152],\n","       [-0.04500719],\n","       [-0.05794093],\n","       [-0.05578531],\n","       [ 0.00133873],\n","       [ 0.03043966],\n","       [ 0.00672779],\n","       [ 0.04660684],\n","       [ 0.02612841],\n","       [ 0.04552903],\n","       [ 0.04013997],\n","       [-0.01806189],\n","       [ 0.01427248],\n","       [ 0.03690653],\n","       [ 0.00349435],\n","       [-0.07087468],\n","       [-0.03315126],\n","       [ 0.09403057],\n","       [ 0.03582872],\n","       [ 0.03151747],\n","       [-0.06548562],\n","       [-0.04177375],\n","       [-0.03961813],\n","       [-0.03854032],\n","       [-0.02560657],\n","       [-0.02345095],\n","       [-0.06656343],\n","       [ 0.03259528],\n","       [-0.046085  ],\n","       [-0.02991782],\n","       [-0.01267283],\n","       [-0.01590626],\n","       [ 0.07139652],\n","       [-0.03099563],\n","       [ 0.00026092],\n","       [ 0.03690653],\n","       [ 0.03906215],\n","       [-0.01482845],\n","       [ 0.00672779],\n","       [-0.06871905],\n","       [-0.00943939],\n","       [ 0.01966154],\n","       [ 0.07462995],\n","       [-0.00836158],\n","       [-0.02345095],\n","       [-0.046085  ],\n","       [ 0.05415152],\n","       [-0.03530688],\n","       [-0.03207344],\n","       [-0.0816528 ],\n","       [ 0.04768465],\n","       [ 0.06061839],\n","       [ 0.05630715],\n","       [ 0.09834182],\n","       [ 0.05954058],\n","       [ 0.03367309],\n","       [ 0.05630715],\n","       [-0.06548562],\n","       [ 0.16085492],\n","       [-0.05578531],\n","       [-0.02452876],\n","       [-0.03638469],\n","       [-0.00836158],\n","       [-0.04177375],\n","       [ 0.12744274],\n","       [-0.07734155],\n","       [ 0.02828403],\n","       [-0.02560657],\n","       [-0.06225218],\n","       [-0.00081689],\n","       [ 0.08864151],\n","       [-0.03207344],\n","       [ 0.03043966],\n","       [ 0.00888341],\n","       [ 0.00672779],\n","       [-0.02021751],\n","       [-0.02452876],\n","       [-0.01159501],\n","       [ 0.02612841],\n","       [-0.05901875],\n","       [-0.03638469],\n","       [-0.02452876],\n","       [ 0.01858372],\n","       [-0.0902753 ],\n","       [-0.00512814],\n","       [-0.05255187],\n","       [-0.02237314],\n","       [-0.02021751],\n","       [-0.0547075 ],\n","       [-0.00620595],\n","       [-0.01698407],\n","       [ 0.05522933],\n","       [ 0.07678558],\n","       [ 0.01858372],\n","       [-0.02237314],\n","       [ 0.09295276],\n","       [-0.03099563],\n","       [ 0.03906215],\n","       [-0.06117437],\n","       [-0.00836158],\n","       [-0.0374625 ],\n","       [-0.01375064],\n","       [ 0.07355214],\n","       [-0.02452876],\n","       [ 0.03367309],\n","       [ 0.0347509 ],\n","       [-0.03854032],\n","       [-0.03961813],\n","       [-0.00189471],\n","       [-0.03099563],\n","       [-0.046085  ],\n","       [ 0.00133873],\n","       [ 0.06492964],\n","       [ 0.04013997],\n","       [-0.02345095],\n","       [ 0.05307371],\n","       [ 0.04013997],\n","       [-0.02021751],\n","       [ 0.01427248],\n","       [-0.03422907],\n","       [ 0.00672779],\n","       [ 0.00457217],\n","       [ 0.03043966],\n","       [ 0.0519959 ],\n","       [ 0.06169621],\n","       [-0.00728377],\n","       [ 0.00564998],\n","       [ 0.05415152],\n","       [-0.00836158],\n","       [ 0.114509  ],\n","       [ 0.06708527],\n","       [-0.05578531],\n","       [ 0.03043966],\n","       [-0.02560657],\n","       [ 0.10480869],\n","       [-0.00620595],\n","       [-0.04716281],\n","       [-0.04824063],\n","       [ 0.08540807],\n","       [-0.01267283],\n","       [-0.03315126],\n","       [-0.00728377],\n","       [-0.01375064],\n","       [ 0.05954058],\n","       [ 0.02181716],\n","       [ 0.01858372],\n","       [-0.01159501],\n","       [-0.00297252],\n","       [ 0.01750591],\n","       [-0.02991782],\n","       [-0.02021751],\n","       [-0.05794093],\n","       [ 0.06061839],\n","       [-0.04069594],\n","       [-0.07195249],\n","       [-0.05578531],\n","       [ 0.04552903],\n","       [-0.00943939],\n","       [-0.03315126],\n","       [ 0.04984027],\n","       [-0.08488624],\n","       [ 0.00564998],\n","       [ 0.02073935],\n","       [-0.00728377],\n","       [ 0.10480869],\n","       [-0.02452876],\n","       [-0.00620595],\n","       [-0.03854032],\n","       [ 0.13714305],\n","       [ 0.17055523],\n","       [ 0.00241654],\n","       [ 0.03798434],\n","       [-0.05794093],\n","       [-0.00943939],\n","       [-0.02345095],\n","       [-0.0105172 ],\n","       [-0.03422907],\n","       [-0.00297252],\n","       [ 0.06816308],\n","       [ 0.00996123],\n","       [ 0.00241654],\n","       [-0.03854032],\n","       [ 0.02612841],\n","       [-0.08919748],\n","       [ 0.06061839],\n","       [-0.02884001],\n","       [-0.02991782],\n","       [-0.0191397 ],\n","       [-0.04069594],\n","       [ 0.01535029],\n","       [-0.02452876],\n","       [ 0.00133873],\n","       [ 0.06924089],\n","       [-0.06979687],\n","       [-0.02991782],\n","       [-0.046085  ],\n","       [ 0.01858372],\n","       [ 0.00133873],\n","       [-0.03099563],\n","       [-0.00405033],\n","       [ 0.01535029],\n","       [ 0.02289497],\n","       [ 0.04552903],\n","       [-0.04500719],\n","       [-0.03315126],\n","       [ 0.097264  ],\n","       [ 0.05415152],\n","       [ 0.12313149],\n","       [-0.08057499],\n","       [ 0.09295276],\n","       [-0.05039625],\n","       [-0.01159501],\n","       [-0.0277622 ],\n","       [ 0.05846277],\n","       [ 0.08540807],\n","       [-0.00081689],\n","       [ 0.00672779],\n","       [ 0.00888341],\n","       [ 0.08001901],\n","       [ 0.07139652],\n","       [-0.02452876],\n","       [-0.0547075 ],\n","       [-0.03638469],\n","       [ 0.0164281 ]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["diabetes_X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUPgMw9k8V23lSkem9miXR","provenance":[]},"kernelspec":{"display_name":"Python 3.8.15 ('ihlt')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"1837759eb970ca00fab7939d441a2c40fff3e44bbf988c5ed37db000776f3ff5"}}},"nbformat":4,"nbformat_minor":0}
