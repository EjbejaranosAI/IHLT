{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pingouin\n",
      "  Downloading pingouin-0.5.2.tar.gz (185 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.4/185.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /home/codespace/.local/lib/python3.10/site-packages (from pingouin) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/codespace/.local/lib/python3.10/site-packages (from pingouin) (1.9.3)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from pingouin) (1.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from pingouin) (3.6.0)\n",
      "Requirement already satisfied: seaborn>=0.11 in /home/codespace/.local/lib/python3.10/site-packages (from pingouin) (0.12.1)\n",
      "Collecting statsmodels>=0.13\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn<1.1.0\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas_flavor>=0.2.0\n",
      "  Downloading pandas_flavor-0.3.0-py3-none-any.whl (6.3 kB)\n",
      "Collecting outdated\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0->pingouin) (2022.6)\n",
      "Collecting lazy-loader==0.1rc2\n",
      "  Downloading lazy_loader-0.1rc2-py3-none-any.whl (5.1 kB)\n",
      "Collecting xarray\n",
      "  Downloading xarray-2022.11.0-py3-none-any.whl (963 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.7/963.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn<1.1.0->pingouin) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn<1.1.0->pingouin) (1.2.0)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=44 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from outdated->pingouin) (58.1.0)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from outdated->pingouin) (2.28.1)\n",
      "Collecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->outdated->pingouin) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->outdated->pingouin) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->outdated->pingouin) (2.1.1)\n",
      "Building wheels for collected packages: pingouin, littleutils\n",
      "  Building wheel for pingouin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pingouin: filename=pingouin-0.5.2-py3-none-any.whl size=196206 sha256=c8c7bfe751095ba8a1402b615df948c65050a1539cb59cb13cbe79c5682947fb\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/bc/2f/87/8bfc7bf126641eab4643a6cd4d887f6ca5ba021ad4b67b3ee0\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=64ecfc28eeb85a806545f91d027860b286aa45c964a6540f2a75d160b5b4147e\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/e0/3b/9c/d55ff5bc6cfbe70537c4731a22f2ee2462c2e5010b56ac9726\n",
      "Successfully built pingouin littleutils\n",
      "Installing collected packages: littleutils, tabulate, patsy, lazy-loader, scikit-learn, outdated, xarray, statsmodels, pandas_flavor, pingouin\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.1.3\n",
      "    Uninstalling scikit-learn-1.1.3:\n",
      "      Successfully uninstalled scikit-learn-1.1.3\n",
      "Successfully installed lazy-loader-0.1rc2 littleutils-0.2.2 outdated-0.2.2 pandas_flavor-0.3.0 patsy-0.5.3 pingouin-0.5.2 scikit-learn-1.0.2 statsmodels-0.13.5 tabulate-0.9.0 xarray-2022.11.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ #\n",
    "# Path test gold directory\n",
    "# ------------------------------ #\n",
    "path = '/content/test-gold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jaccard_lesk(sentence1: str, sentence2: str):\n",
    "\n",
    "  # Apply lesk to sentence 1\n",
    "  synset1 = [ lesk(sentence1, word) for word in sentence1 ]\n",
    "  synset1 = { word for word in synset1 if word is not None }\n",
    "\n",
    "  # Apply lesk to sentence 1\n",
    "  synset2 = [ lesk(sentence2, word) for word in sentence2 ]\n",
    "  synset2 = { word for word in synset2 if word is not None }\n",
    "\n",
    "  # Calculate distance\n",
    "  distance = jaccard_distance(synset1, synset2)\n",
    "\n",
    "  return distance\n",
    "\n",
    "# ------------------------------ #\n",
    "# Lemmatization text process\n",
    "# ------------------------------ #\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"NN\": \"n\",\n",
    "                \"NNS\": \"n\",\n",
    "                \"NNP\": \"n\",\n",
    "                \"NNPS\": \"n\",\n",
    "                \"VB\": \"v\",\n",
    "                \"VBD\": \"v\",\n",
    "                \"VBG\": \"v\",\n",
    "                \"VBN\": \"v\",\n",
    "                \"VBP\": \"v\",\n",
    "                \"VBZ\": \"v\",\n",
    "                \"RB\": \"r\",\n",
    "                \"RBR\": \"r\",\n",
    "                \"RBS\": \"r\",\n",
    "                \"JJ\": \"a\",\n",
    "                \"JJR\": \"a\",\n",
    "                \"JJS\": \"a\",}\n",
    "        \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize(column):\n",
    "  return  [ list(lemmatizer.lemmatize(word.lower(), get_wordnet_pos(word.lower())) for word in nltk.word_tokenize(sentence)) for sentence in column ]  \n",
    "\n",
    "# ------------------------------ #\n",
    "# Similarity Function\n",
    "# ------------------------------ #\n",
    "def jaccard_similarity(s1, s2):\n",
    "  intersection = len(s1.intersection(s2))\n",
    "  union = len(s1) + len(s2) - intersection\n",
    "  return float(intersection) / float(union)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#---------------------------------------------#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# (Similarity-gold score) Pearson Correlation #\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#---------------------------------------------#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pearson_corr \u001b[39m=\u001b[39m (pearsonr(df[\u001b[39m'\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mgs\u001b[39m\u001b[39m'\u001b[39m]))[\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPearson\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms correlation Lab 2: \u001b[39m\u001b[39m\"\u001b[39m,pearson_corr)\n\u001b[1;32m      7\u001b[0m \u001b[39m#--------------------------------------------------#\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# (LemmaSimilarity-gold score) Pearson Correlation #\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m#--------------------------------------------------#\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------#\n",
    "# (Similarity-gold score) Pearson Correlation #\n",
    "#---------------------------------------------#\n",
    "pearson_corr = (pearsonr(df['similarity'], df['gs']))[0]\n",
    "print(f\"Pearson's correlation Lab 2: \",pearson_corr)\n",
    "\n",
    "#--------------------------------------------------#\n",
    "# (LemmaSimilarity-gold score) Pearson Correlation #\n",
    "#--------------------------------------------------#\n",
    "pearson_corr_Lemma = (pearsonr(df['Lemma_similarity'], df['gs']))[0]\n",
    "print(f\"Pearson's correlation Lab 3: \",pearson_corr_Lemma)\n",
    "\n",
    "#--------------------------------------------#\n",
    "#         (Lesk-Gs) Pearson Correlation\n",
    "#--------------------------------------------#\n",
    "#df['gs'] = df['gs'].fillna(0)\n",
    "pearson_corr_Lesk = (pearsonr(df['LeskSimilarity'], df['gs']))[0]\n",
    "print(f\"Pearson's correlation Lab 6: \",pearson_corr_Lesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
